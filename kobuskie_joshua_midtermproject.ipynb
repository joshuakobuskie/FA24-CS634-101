{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS634-101 Midterm Project - Apriori Algorithm\n",
    "\n",
    "**Author** : *Joshua Kobuskie*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Details\n",
    "1. Create 10 (or any number of, not less than 5) items usually seen in\n",
    "Amazon, K-mart, or any other supermarkets (e.g. diapers, clothes, etc.).\n",
    "2. Create a database of at least 20 transactions each containing some of these\n",
    "items. Save the transaction in a CSV file.\n",
    "3. Repeat (1) by creating 4 additional, different databases each containing at\n",
    "least 20 transactions.\n",
    "4. Note: You can create these transactions and datasets manually, download\n",
    "them from the net, or use the examples I will provide. In any case, add a\n",
    "note to your report where and how you built your data sets.\n",
    "5. The items and transaction must not be random so that your code is\n",
    "deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Initialization: ###\n",
    "Prior to beginning the program, transactional data was initialized for each store. A dataset was created for each of the retail stores represented and this data is saved into CSV files for future use. The \"amazonTransactions.csv\", \"bestBuyTransactions.csv\", \"kMartTransactions.csv\", \"nikeTransactions.csv\", \"genericTransactions.csv\", \"customTransactions.csv\", and \"walmartTransactions.csv\" files must be present in the current directory in order for the program to run properly. Datasets 1 through 6 have been created based on the examples provided. Dataset 7 has been built using GenAI, and contains 1000 transactions with 30 unique items to simulate Walmart transactional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Details\n",
    "* Implement the brute force method to generate frequent items and generate\n",
    "association rules.\n",
    "* The brute force method for finding frequent itemsets works as follows.\n",
    "Enumerate and generate all possible 1-itemsets and 2-itemsets. There are\n",
    "30 items, so there are 435 possible 2-itemsets totally. Check to see whether\n",
    "each possible 1-itemset/2-itemset is frequent. Then enumerate and generate\n",
    "all possible 3-itemsets. There are 4060 possible 3-itemsets totally. Check to\n",
    "see whether each possible 3-itemset is :frequent. Keep on doing so until\n",
    "you see none of the possible k-itemsets is :frequent for some k, at which\n",
    "point the brute force method terminates without generating (k+1)-itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Selection and Validation: ###\n",
    "Upon start, the user is welcomed to the Apriori Algorithm on the command line and prompted to enter the following user specified variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determination of Dataset: ###\n",
    "The user is provided with a list of datasets and is prompted to enter an integer value between 1 and 7 on the command line to select the corresponding dataset. If a value outside of this range or a non-integer value is entered, an error is created and the program terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS634-101 Apriori Midterm Project - Joshua Kobuskie\n",
      "You have selected dataset 1: Amazon\n"
     ]
    }
   ],
   "source": [
    "# The data set selection, support, and confidence must be user-specified parameters\n",
    "\n",
    "# Start and take in user input\n",
    "\n",
    "print(\"CS634-101 Apriori Midterm Project - Joshua Kobuskie\")\n",
    "\n",
    "dataSelect = input(\"Please select a dataset by number: \\n1. Amazon \\n2. Best Buy \\n3. K-Mart \\n4. Nike \\n5. Generic \\n6. Custom\\n7. Walmart\\n\")\n",
    "\n",
    "# Confirm selection is valid\n",
    "try:\n",
    "    dataSelect = int(dataSelect)\n",
    "    if dataSelect not in range(1,8):\n",
    "        print(\"Invalid input. Please restart and enter a valid dataset number.\")\n",
    "        raise SystemExit\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Please restart and enter a valid dataset number.\")\n",
    "    raise SystemExit\n",
    "\n",
    "datasets = [\"Amazon\", \"Best Buy\", \"K-Mart\", \"Nike\", \"Generic\", \"Custom\", \"Walmart\"]\n",
    "\n",
    "print(\"You have selected dataset {}: {}\".format(dataSelect, datasets[dataSelect-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determination of Support: ###\n",
    "The user is prompted to enter an integer value between 1 and 100 on the command line to select the minimum support. If a value outside of this range or a non-integer value is entered, an error is created and the program terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected a minimum support level of 50%\n"
     ]
    }
   ],
   "source": [
    "support = input(\"Please select the minimum support level in % (value 1 to 100):\\n\")\n",
    "\n",
    "# Confirm selection is valid\n",
    "try:\n",
    "    support = int(support)\n",
    "    if support not in range(1,101):\n",
    "        print(\"Invalid input. Please restart and enter a valid support level.\")\n",
    "        raise SystemExit\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Please restart and enter a valid support level.\")\n",
    "    raise SystemExit\n",
    "\n",
    "print(\"You have selected a minimum support level of {}%\".format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determination of Confidence: ###\n",
    "The user is prompted to enter an integer value between 1 and 100 on the command line to select the minimum confidence. If a value outside of this range or a non-integer value is entered, an error is created and the program terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected a minimum confidence level of 50%\n"
     ]
    }
   ],
   "source": [
    "confidence = input(\"Please select the minimum confidence level in % (value 1 to 100):\\n\")\n",
    "\n",
    "# Confirm selection is valid\n",
    "try:\n",
    "    confidence = int(confidence)\n",
    "    if confidence not in range(1,101):\n",
    "        print(\"Invalid input. Please restart and enter a valid confidence level.\")\n",
    "        raise SystemExit\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Please restart and enter a valid confidence level.\")\n",
    "    raise SystemExit\n",
    "\n",
    "print(\"You have selected a minimum confidence level of {}%\".format(confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing: ###\n",
    "The support and confidence levels entered by the user are converted into a float representing the percentage of support and confidence required. The selected dataset is loaded from the corresponding CSV file, and each transaction is read into an array for future traversal. The set of unique items is generated from the array of transactions by traversing all transactions and adding each unique item to the set. A frequent itemsets dictionary is also initialized to store the frequent itemsets and the support for each itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing: ###\n",
    "To time the execution of each algorithm, the time library was used. The start time is recorded when preprocessing has been completed and the algorithm begins identifying frequent itemsets and association rules. The stop time is then determined for both the frequent itemset identification and the association rule identification at the end of printing the frequent itemsets and at the end of printing the association rules, respectively. The time to determine frequent itemsets and the time to determine association rules is then calculated as the difference between the stop and start times, and this is calculated for each of the three algorithms and printed to the user on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open selected sets and transactions\n",
    "import itertools\n",
    "import time\n",
    "import csv\n",
    "\n",
    "support /= 100\n",
    "confidence /= 100\n",
    "\n",
    "transactions = [\"amazonTransactions.csv\", \"bestBuyTransactions.csv\", \"kMartTransactions.csv\", \"nikeTransactions.csv\", \"genericTransactions.csv\", \"customTransactions.csv\", \"walmartTransactions.csv\"]\n",
    "\n",
    "with open(transactions[dataSelect-1], mode ='r') as file:\n",
    "  csvFile = csv.reader(file)\n",
    "  curTrans = []\n",
    "  for line in csvFile:\n",
    "    curTrans.append(line)\n",
    "\n",
    "# All implementations will start with the data in curTrans\n",
    "# Begin timing from here for comparison\n",
    "bruteFreqTime = time.time()\n",
    "\n",
    "# Having the starting sets is redundant. Removing and just find unique items in transactions\n",
    "\n",
    "curSet = set()\n",
    "for trans in curTrans:\n",
    "  for item in trans:\n",
    "    # Will only add if the item has not been encountered yet since it is a set\n",
    "    curSet.add(item)\n",
    "\n",
    "frequentItems = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over Candidate Itemsets of Size K: ###\n",
    "Using a brute force method, candidate itemsets of size K will be created, starting with K=1 and increasing by 1 during each iteration. Candidate itemset generation is repeated only if at least 1 frequent itemset was found for the previous value of K and the candidate itemset size does not exceed the number of unique items. \n",
    "\n",
    "* ### Computer Combinations: ###\n",
    "Using the itertools library, the candidate set of K-itemsets is created by calculating the combinations of the unique itemset of the specified size K. Each combination is then searched for within the transactional array, and its frequency is calculated.\n",
    "\n",
    "* ### Check Support and Store Frequency: ###\n",
    "If the frequency divided by the total number of transactions for a given candidate itemset is greater than or equal to the support value specified by the user, the itemset is considered to be frequent and the itemset and support level are stored in the frequent itemsets dictionary as a key-value pair. If a frequent itemset is found, the looping parameter will also be updated to ensure exploration of the next set of candidate itemsets of size K+1.\n",
    "\n",
    "* ### Update Candidate Set Size to K+1: ###\n",
    "After checking all candidate itemsets of size K, the candidate set size will be incremented by 1 from K to K+1. The program begins the iteration process again, performing the same evaluation to determine if any frequent itemsets were found during the prior iteration. If no frequent itemsets were found, the program will terminate and not explore any larger K-itemsets based on the Apriori Principle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all sizes of combinations until one is not found or reach max len\n",
    "# Originally was going to limit the size of the combinations as being checked, but upon review realized that this was not truly brute force\n",
    "# Removed optimization\n",
    "\n",
    "found = 1\n",
    "i = 1\n",
    "while (i <= len(curSet) and found > 0):\n",
    "  found = 0\n",
    "\n",
    "  # For each combination of size i\n",
    "  for combination in itertools.combinations(curSet, i):\n",
    "    # Count support of combination by iterating through the transactions\n",
    "    count = 0\n",
    "\n",
    "    for trans in curTrans:\n",
    "      # Cast combination to a set to use the issubset function\n",
    "      # Check if combination occurs in transaction and incriment count\n",
    "      if set(combination).issubset(trans):\n",
    "        count += 1\n",
    "    \n",
    "    if count/len(curTrans) >= support:\n",
    "      # Save frequent items\n",
    "      frequentItems[combination] = count/len(curTrans)\n",
    "      # Found at least one frequent item in this size of combinations\n",
    "      found += 1\n",
    "\n",
    "  # Check next combination size\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Frequent Itemsets: ###\n",
    "For each itemset identified as frequent and stored in the frequent itemsets dictionary, the frequent itemset and support value for that itemset are printed to the user on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brute Force Frequent Itemsets\n",
      "\n",
      "Frequent Itemset 1: [Android Programming: The Big Nerd Ranch]\n",
      "Support: 65.00%\n",
      "\n",
      "Frequent Itemset 2: [Java For Dummies]\n",
      "Support: 65.00%\n",
      "\n",
      "Frequent Itemset 3: [A Beginner’s Guide]\n",
      "Support: 55.00%\n",
      "\n",
      "Frequent Itemset 4: [Java: The Complete Reference]\n",
      "Support: 50.00%\n",
      "\n",
      "Frequent Itemset 5: [Java For Dummies, Java: The Complete Reference]\n",
      "Support: 50.00%\n",
      "\n",
      "Generated Brute Force Frequent Itemsets in 0.022836923599243164 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBrute Force Frequent Itemsets\\n\")\n",
    "\n",
    "for i, (items, supp) in enumerate(frequentItems.items()):\n",
    "    print(\"Frequent Itemset {}: [{}]\\nSupport: {:0.2f}%\\n\".format(i+1, \", \".join(items), supp*100))\n",
    "\n",
    "# Frequent items generated, end timing\n",
    "bruteFreqTime = time.time() - bruteFreqTime\n",
    "\n",
    "print(\"Generated Brute Force Frequent Itemsets in {} seconds\".format(bruteFreqTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over Frequent Itemsets to Find Association Rules: ###\n",
    "An association rules array is initialized to store association rules as discovered. The stored frequent itemsets previously discovered are now iterated over for all itemsets with at least 2 unique items. \n",
    "\n",
    "* ### Generate Increasing Large Combinations as an Antecedent for each Itemset: ###\n",
    "Each frequent itemset is composed of unique items. All subsets of the current frequent itemset being evaluated will be generated, starting with subsets of size 1 and increasing until one less than the size of the frequent itemset. Each subset generated will represent the antecedent in the association rules to be tested. For each antecedent, which must be a frequent itemset previously explored due to the Apriori Principle, the support of the itemset can be divided by the support of the antecedent by finding their associated values in the frequent itemsets dictionary. The resulting value is the confidence of the association rule.\n",
    "\n",
    "* ### Check Confidence and Store Association Rules: ###\n",
    "If the confidence of the association rule is greater than or equal to the user specified confidence level, the consequent can be calculated by removing the antecedent from the itemset, and the association rule is stored as the antecedent, consequent, confidence, and support in a tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteRuleTime = time.time()\n",
    "\n",
    "associationRules = []\n",
    "\n",
    "for itemset in frequentItems:\n",
    "    if len(itemset) > 1:\n",
    "\n",
    "        # For all subsets of the itemset\n",
    "        for i in range(1, len(itemset)):\n",
    "            for ant in itertools.combinations(itemset, i):\n",
    "                # Check confidence\n",
    "                if frequentItems[itemset]/frequentItems[ant] >= confidence:\n",
    "                    cons = tuple(set(itemset) - set(ant))\n",
    "                    # Store antecedent, consequent, confidence, support\n",
    "                    associationRules.append((ant, cons, frequentItems[itemset]/frequentItems[ant], frequentItems[itemset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Association Rules: ###\n",
    "For each association rule identified and stored in the association rules array, the antecedent, consequent, confidence, and support is printed to the user on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brute Force Association Rules\n",
      "\n",
      "Association Rule 1: [Java For Dummies] -> [Java: The Complete Reference]\n",
      "Confidence: 76.92%\n",
      "Support: 50.00%\n",
      "\n",
      "Association Rule 2: [Java: The Complete Reference] -> [Java For Dummies]\n",
      "Confidence: 100.00%\n",
      "Support: 50.00%\n",
      "\n",
      "Generated Brute Force Association Rules in 0.010598897933959961 seconds\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBrute Force Association Rules\\n\")\n",
    "\n",
    "for i in range(len(associationRules)):\n",
    "    print(\"Association Rule {}: [{}] -> [{}]\\nConfidence: {:0.2f}%\\nSupport: {:0.2f}%\\n\".format(i+1, \", \".join(associationRules[i][0]), \", \".join(associationRules[i][1]), associationRules[i][2]*100, associationRules[i][3]*100))\n",
    "\n",
    "# Association rules generated, end timing\n",
    "bruteRuleTime = time.time() - bruteRuleTime\n",
    "print(\"Generated Brute Force Association Rules in {} seconds\".format(bruteRuleTime))\n",
    "print(\"#\"*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Details\n",
    "Use an existing Apriori implementation from Python libraries/packages to\n",
    "verify the results from your brute force algorithm implementation.\n",
    "* Use Python existing package for fpgrowth (as known as fp-tree algorithm)\n",
    "to generate the items and rules.\n",
    "* Compare the results from your brute-force, Apriori, and FP-Tree/Growth.\n",
    "* Do the three algorithms produce the same results?\n",
    "* Report the timing performance for all three algorithms as well.\n",
    "* Which one is faster?\n",
    "So, for all three algorithms, generate and print out all the association rules and\n",
    "the input transactions for each of the 5 transactional databases you created/used.\n",
    "The data set selection, support, and confidence must be user-specified\n",
    "parameters, so the output should show different rules with respect to different\n",
    "databases and different support/confidence.\n",
    "Make sure to show multiple support and confidence results for each data set.\n",
    "You should prompt the user only once for the input and reuse for the three\n",
    "algorithms in each run.\n",
    "The items and transactions must be clear and easy to identify. Your\n",
    "program should show the performance time for each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Evaluation: ###\n",
    "The accuracy of my brute force implementation is verified by comparing the results of two library-based implementations of the Apriori and FP-growth algorithm to determine frequent itemsets and association rules. The time taken to execute each of these methods is then compared to illustrate the differences in execution time for each implementation.\n",
    "\n",
    "* ### Existing Libraries used to Validate: ###\n",
    "The mlxtend library was used to validate the results of my brute force implementation. The same dataset, support, and confidence as previously specified by the user are used to inform the Apriori and FP-Growth algorithms and recalculate the frequent itemsets. This information is then passed to the mlxtend association rule function to determine the association rules for both the Apriori and FP-Growth algorithms. The same print output is generated by iterating through the output of each algorithm.\n",
    "\n",
    "* ### Difference in Data Representation: ###\n",
    "A notable difference in the implementation of my brute force algorithm and the mlxtend implementations is the use of a pandas dataframe. My implementation of the brute force algorithm relies on a 2D array to represent the transactions, where the mlxtend algorithms take in a pandas dataframe. To create this dataframe, the transactions were first encoded and transformed to ensure equal dimensions in each transaction in the dataframe. This difference does not impact the data itself, but does change how it is represented and stored. The use of a pandas dataframe may have an influence on the timing of these algorithms as compared to the use of a 2D array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apriori Frequent Itemsets\n",
      "\n",
      "Frequent Itemset 1: [A Beginner’s Guide]\n",
      "Support: 55.00%\n",
      "\n",
      "Frequent Itemset 2: [Android Programming: The Big Nerd Ranch]\n",
      "Support: 65.00%\n",
      "\n",
      "Frequent Itemset 3: [Java For Dummies]\n",
      "Support: 65.00%\n",
      "\n",
      "Frequent Itemset 4: [Java: The Complete Reference]\n",
      "Support: 50.00%\n",
      "\n",
      "Frequent Itemset 5: [Java For Dummies, Java: The Complete Reference]\n",
      "Support: 50.00%\n",
      "\n",
      "Generated Apriori Frequent Itemsets in 0.005824089050292969 seconds\n"
     ]
    }
   ],
   "source": [
    "import mlxtend\n",
    "import mlxtend.frequent_patterns\n",
    "import mlxtend.preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "transEncoder = mlxtend.preprocessing.TransactionEncoder()\n",
    "transEncoderArr = transEncoder.fit(curTrans).transform(curTrans)\n",
    "transDF = pd.DataFrame(transEncoderArr, columns=transEncoder.columns_)\n",
    "\n",
    "# Begin timing from here for comparison\n",
    "aprioriFreqTime = time.time()\n",
    "\n",
    "aprioriFreqItems = mlxtend.frequent_patterns.apriori(transDF, min_support=support, use_colnames=True)\n",
    "\n",
    "print(\"\\nApriori Frequent Itemsets\\n\")\n",
    "\n",
    "for index, row in aprioriFreqItems.iterrows():\n",
    "    print(\"Frequent Itemset {}: [{}]\\nSupport: {:0.2f}%\\n\".format(index+1, \", \".join(row[\"itemsets\"]), row[\"support\"]*100))\n",
    "\n",
    "aprioriFreqTime =  time.time() - aprioriFreqTime\n",
    "\n",
    "print(\"Generated Apriori Frequent Itemsets in {} seconds\".format(aprioriFreqTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apriori Association Rules\n",
      "\n",
      "Association Rule 1: [Java For Dummies] -> [Java: The Complete Reference]\n",
      "Confidence: 76.92%\n",
      "Support: 50.00%\n",
      "\n",
      "Association Rule 2: [Java: The Complete Reference] -> [Java For Dummies]\n",
      "Confidence: 100.00%\n",
      "Support: 50.00%\n",
      "\n",
      "Generated Apriori Association Rules in 0.004627227783203125 seconds\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "aprioriRulesTime = time.time()\n",
    "\n",
    "if not aprioriFreqItems.empty:\n",
    "    aprioriRules = mlxtend.frequent_patterns.association_rules(aprioriFreqItems, metric=\"confidence\", min_threshold=confidence)\n",
    "else:\n",
    "    aprioriRules = pd.DataFrame(columns=[\"antecedents\", \"consequents\", \"confidence\", \"support\"])\n",
    "\n",
    "print(\"\\nApriori Association Rules\\n\")\n",
    "\n",
    "for index, row in aprioriRules.iterrows():\n",
    "    print(\"Association Rule {}: [{}] -> [{}]\\nConfidence: {:0.2f}%\\nSupport: {:0.2f}%\\n\".format(index+1, \", \".join(row[\"antecedents\"]), \", \".join(row[\"consequents\"]), row[\"confidence\"]*100, row[\"support\"]*100))\n",
    "\n",
    "aprioriRulesTime = time.time() - aprioriRulesTime\n",
    "\n",
    "print(\"Generated Apriori Association Rules in {} seconds\".format(aprioriRulesTime))\n",
    "print(\"#\"*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FP-Growth Frequent Itemsets\n",
      "\n",
      "Frequent Itemset 1: [Java For Dummies]\n",
      "Support: 65.00%\n",
      "\n",
      "Frequent Itemset 2: [Android Programming: The Big Nerd Ranch]\n",
      "Support: 65.00%\n",
      "\n",
      "Frequent Itemset 3: [A Beginner’s Guide]\n",
      "Support: 55.00%\n",
      "\n",
      "Frequent Itemset 4: [Java: The Complete Reference]\n",
      "Support: 50.00%\n",
      "\n",
      "Frequent Itemset 5: [Java For Dummies, Java: The Complete Reference]\n",
      "Support: 50.00%\n",
      "\n",
      "Generated FP-Growth Frequent Itemsets in 0.0033779144287109375 seconds\n"
     ]
    }
   ],
   "source": [
    "# Begin timing from here for comparison\n",
    "fpFreqTime = time.time()\n",
    "\n",
    "fpFreqItems = mlxtend.frequent_patterns.fpgrowth(transDF, min_support=support, use_colnames=True)\n",
    "\n",
    "print(\"\\nFP-Growth Frequent Itemsets\\n\")\n",
    "\n",
    "for index, row in fpFreqItems.iterrows():\n",
    "    print(\"Frequent Itemset {}: [{}]\\nSupport: {:0.2f}%\\n\".format(index+1, \", \".join(row[\"itemsets\"]), row[\"support\"]*100))\n",
    "\n",
    "fpFreqTime =  time.time() - fpFreqTime\n",
    "\n",
    "print(\"Generated FP-Growth Frequent Itemsets in {} seconds\".format(fpFreqTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FP-Growth Association Rules\n",
      "\n",
      "Association Rule 1: [Java For Dummies] -> [Java: The Complete Reference]\n",
      "Confidence: 76.92%\n",
      "Support: 50.00%\n",
      "\n",
      "Association Rule 2: [Java: The Complete Reference] -> [Java For Dummies]\n",
      "Confidence: 100.00%\n",
      "Support: 50.00%\n",
      "\n",
      "Generated FP-Growth Association Rules in 0.004705905914306641 seconds\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "fpRulesTime = time.time()\n",
    "\n",
    "if not fpFreqItems.empty:\n",
    "    fpRules = mlxtend.frequent_patterns.association_rules(fpFreqItems, metric=\"confidence\", min_threshold=confidence)\n",
    "else:\n",
    "    fpRules = pd.DataFrame(columns=[\"antecedents\", \"consequents\", \"confidence\", \"support\"])\n",
    "\n",
    "print(\"\\nFP-Growth Association Rules\\n\")\n",
    "\n",
    "for index, row in fpRules.iterrows():\n",
    "    print(\"Association Rule {}: [{}] -> [{}]\\nConfidence: {:0.2f}%\\nSupport: {:0.2f}%\\n\".format(index+1, \", \".join(row[\"antecedents\"]), \", \".join(row[\"consequents\"]), row[\"confidence\"]*100, row[\"support\"]*100))\n",
    "\n",
    "fpRulesTime = time.time() - fpRulesTime\n",
    "\n",
    "print(\"Generated FP-Growth Association Rules in {} seconds\".format(fpRulesTime))\n",
    "print(\"#\"*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 Details\n",
    "Github & Jupyter Notebook.\n",
    "* After you finish your code in development and testing\n",
    "and make sure it works, and prepare the report (meaning\n",
    "all heavy lifting job is done ), Create a Github\n",
    "repository in https://github.com/. Your account must be\n",
    "with your NJIT email not your personal email (unless if\n",
    "you have to, but indicate that in your report as well).\n",
    "* Load your project to the repository.\n",
    "* Create Jupyter notebook for your work to show the\n",
    "output, for more info visit https://jupyter.org/\n",
    "* Give me ya54@njit.edu access as a collaborator to your\n",
    "repository. (If we have a grader, you give him/her access\n",
    "too).\n",
    "* Add Github link to your repository to your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
